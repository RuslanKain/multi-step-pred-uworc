--neurons = 283||layers = 1||lookback = 77||dropout = 0.4||learning rate = 0.05168524755953025||epochs = 141||batch_size = 213||number of lstm/conv1d layers = 3||number of pool size = 2||activation function = tanh||optimizer = Adagrad||model type = with lstm--