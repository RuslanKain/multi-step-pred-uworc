--neurons = 67||layers = 2||lookback = 2||dropout = 0.0||learning rate = 0.17502011427403652||epochs = 27||batch_size = 1||number of lstm/conv1d layers = 2||number of pool size = 1||activation function = relu||optimizer = Adagrad||model type = with lstm--